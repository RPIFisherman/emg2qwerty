{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvxJOJu4XUIW"
      },
      "source": [
        "### Step 1: Mount the Google Drive\n",
        "\n",
        "Remember to use GPU runtime before mounting your Google Drive. (Runtime --> Change runtime type)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCSU4HrvkVDq",
        "outputId": "331f9c7f-e786-450f-924e-3e441a31cea5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoSL1U8Xbjh"
      },
      "source": [
        "### Step 2: Open the project directory\n",
        "\n",
        "Replace `Your_Dir` with your own path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gfQ17SmkfOK",
        "outputId": "dea66098-e2d2-460b-e232-551c0624a90f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: cd: drive/MyDrive/emg2qwerty: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cd drive/MyDrive/emg2qwerty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzYfAOEYN4C"
      },
      "source": [
        "### Step 3: Install required packages\n",
        "\n",
        "After installing them, Colab will require you to restart the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFFKvhs4tAp5",
        "outputId": "1b8e7b9f-7013-4d76-c975-46a4524a1388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/stepanhruda/camel-kenlm.git@a6e906b2b30497dd999cb9c84c42c5111f8616e0 (from -r requirements.txt (line 31))\n",
            "  Cloning https://github.com/stepanhruda/camel-kenlm.git (to revision a6e906b2b30497dd999cb9c84c42c5111f8616e0) to /tmp/pip-req-build-_cwwz_kn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/stepanhruda/camel-kenlm.git /tmp/pip-req-build-_cwwz_kn\n",
            "  Running command git rev-parse -q --verify 'sha^a6e906b2b30497dd999cb9c84c42c5111f8616e0'\n",
            "  Running command git fetch -q https://github.com/stepanhruda/camel-kenlm.git a6e906b2b30497dd999cb9c84c42c5111f8616e0\n",
            "  Running command git checkout -q a6e906b2b30497dd999cb9c84c42c5111f8616e0\n",
            "  Resolved https://github.com/stepanhruda/camel-kenlm.git to commit a6e906b2b30497dd999cb9c84c42c5111f8616e0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: datasets==2.19.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.19.2)\n",
            "Requirement already satisfied: h5py==3.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.11.0)\n",
            "Requirement already satisfied: hydra-core==1.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: hydra-submitit-launcher==1.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: hypothesis==6.97.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (6.97.6)\n",
            "Requirement already satisfied: lightning-bolts==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: mne-bids==0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.15.0)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (3.8.1)\n",
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.24.4)\n",
            "Requirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2.3.0)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.0.3)\n",
            "Requirement already satisfied: pip==24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (24.0)\n",
            "Requirement already satisfied: pre-commit==3.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (3.7.1)\n",
            "Requirement already satisfied: pytest-benchmark==4.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.0.0)\n",
            "Requirement already satisfied: pytest-cov==5.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (5.0.0)\n",
            "Requirement already satisfied: pytest-env==1.1.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (1.1.3)\n",
            "Requirement already satisfied: pytest-mock==3.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (3.14.0)\n",
            "Requirement already satisfied: pytest-rerunfailures==14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (14.0)\n",
            "Requirement already satisfied: pytest-xdist==3.5.0 in /usr/local/lib/python3.11/dist-packages (from pytest-xdist[psutil]==3.5.0->-r requirements.txt (line 20)) (3.5.0)\n",
            "Requirement already satisfied: pytest==7.4.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (7.4.4)\n",
            "Requirement already satisfied: python-levenshtein==0.12.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (0.12.2)\n",
            "Requirement already satisfied: pytorch-lightning==1.8.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (1.8.6)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (2.3.0)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (1.10.1)\n",
            "Requirement already satisfied: setuptools==69.5.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (69.5.1)\n",
            "Requirement already satisfied: torchaudio==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.3.0)\n",
            "Requirement already satisfied: torchmetrics==0.11.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.11.4)\n",
            "Requirement already satisfied: trio==0.23.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (0.23.2)\n",
            "Requirement already satisfied: unidecode==1.3.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (1.3.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.2->-r requirements.txt (line 2)) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.19.2->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core==1.3.2->-r requirements.txt (line 4)) (4.9.3)\n",
            "Requirement already satisfied: submitit>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from hydra-submitit-launcher==1.2.0->-r requirements.txt (line 5)) (1.5.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from hypothesis==6.97.6->-r requirements.txt (line 6)) (25.1.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from hypothesis==6.97.6->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: lightning-utilities>0.3.1 in /usr/local/lib/python3.11/dist-packages (from lightning-bolts==0.7.0->-r requirements.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning-bolts==0.7.0->-r requirements.txt (line 7)) (0.18.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from lightning-bolts==0.7.0->-r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: mne>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne-bids==0.15.0->-r requirements.txt (line 8)) (1.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1->-r requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1->-r requirements.txt (line 9)) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->-r requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->-r requirements.txt (line 12)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->-r requirements.txt (line 12)) (2025.1)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit==3.7.1->-r requirements.txt (line 14)) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit==3.7.1->-r requirements.txt (line 14)) (2.6.9)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit==3.7.1->-r requirements.txt (line 14)) (1.9.1)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit==3.7.1->-r requirements.txt (line 14)) (20.29.3)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from pytest-benchmark==4.0.0->-r requirements.txt (line 15)) (9.0.0)\n",
            "Requirement already satisfied: coverage>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from coverage[toml]>=5.2.1->pytest-cov==5.0.0->-r requirements.txt (line 16)) (7.6.12)\n",
            "Requirement already satisfied: execnet>=1.1 in /usr/local/lib/python3.11/dist-packages (from pytest-xdist==3.5.0->pytest-xdist[psutil]==3.5.0->-r requirements.txt (line 20)) (2.1.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest==7.4.4->-r requirements.txt (line 21)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from pytest==7.4.4->-r requirements.txt (line 21)) (1.5.0)\n",
            "Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 23)) (2.6.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 23)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 24)) (2.3.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio==0.23.2->-r requirements.txt (line 29)) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio==0.23.2->-r requirements.txt (line 29)) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio==0.23.2->-r requirements.txt (line 29)) (1.3.1)\n",
            "Requirement already satisfied: psutil>=3.0 in /usr/local/lib/python3.11/dist-packages (from pytest-xdist[psutil]==3.5.0->-r requirements.txt (line 20)) (5.9.5)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->-r requirements.txt (line 24)) (12.5.82)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.2->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.2->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.2->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.2->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.2->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.19.2->-r requirements.txt (line 2)) (1.18.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne>=1.5->mne-bids==0.15.0->-r requirements.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne>=1.5->mne-bids==0.15.0->-r requirements.txt (line 8)) (0.4)\n",
            "Collecting matplotlib>=3.6 (from mne>=1.5->mne-bids==0.15.0->-r requirements.txt (line 8))\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne>=1.5->mne-bids==0.15.0->-r requirements.txt (line 8)) (1.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.3->-r requirements.txt (line 12)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.1->datasets==2.19.2->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.1->datasets==2.19.2->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.1->datasets==2.19.2->-r requirements.txt (line 2)) (2025.1.31)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit>=1.3.3->hydra-submitit-launcher==1.2.0->-r requirements.txt (line 5)) (3.1.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts==0.7.0->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts==0.7.0->-r requirements.txt (line 7)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts==0.7.0->-r requirements.txt (line 7)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts==0.7.0->-r requirements.txt (line 7)) (4.25.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts==0.7.0->-r requirements.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts==0.7.0->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.10.0->lightning-bolts==0.7.0->-r requirements.txt (line 7)) (11.1.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit==3.7.1->-r requirements.txt (line 14)) (0.3.9)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit==3.7.1->-r requirements.txt (line 14)) (4.3.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0->-r requirements.txt (line 24)) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0->-r requirements.txt (line 24)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.5->mne-bids==0.15.0->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.5->mne-bids==0.15.0->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.5->mne-bids==0.15.0->-r requirements.txt (line 8)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.5->mne-bids==0.15.0->-r requirements.txt (line 8)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.5->mne-bids==0.15.0->-r requirements.txt (line 8)) (3.2.1)\n",
            "Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: matplotlib\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "pymc 5.20.1 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSoRzGXCfUtz"
      },
      "source": [
        "### Step 4: Start your experiments!\n",
        "\n",
        "- Remember to download and copy the dataset to this directory: `Your_Dir/emg2qwerty/data`.\n",
        "- You may now start your experiments with any scripts! Below are examples of single-user training and testing (greedy decoding).\n",
        "- **There are two ways to track the logs:**\n",
        "  - 1. Keep `--multirun`, and the logs will not be printed here, but they will be saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/submitit_logs/`.\n",
        "  - 2. Comment out `--multirun` and the logs will be printed in this notebook, but they will not be saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVuSn4rXhLJa"
      },
      "source": [
        "#### Training\n",
        "\n",
        "- The checkpoints are saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/checkpoints/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZeUfuK8rLjQ",
        "outputId": "2cfd1627-2241-4c4f-f868-0fc1e6550836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: jax 0.5.2\n",
            "Uninstalling jax-0.5.2:\n",
            "  Successfully uninstalled jax-0.5.2\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall jax -y\n",
        "!python -c \"import pl_bolts; print(pl_bolts.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n84M6KLmkp2i",
        "outputId": "4abfe7fd-ec17-40e6-e74d-0e6896b83b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-14 16:14:48,505][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-14 16:14:48,516][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-14 16:14:50,979][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/usr/local/lib/python3.11/dist-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 5.3 M \n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "5.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "5.3 M     Total params\n",
            "21.173    Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Epoch 0:  94% 120/127 [03:08<00:11,  1.57s/it, loss=122, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 127/127 [03:14<00:00,  1.53s/it, loss=122, v_num=0]\n",
            "Epoch 0: 100% 127/127 [03:14<00:00,  1.53s/it, loss=122, v_num=0]Epoch 0, global step 120: 'val/CER' reached 1358.08594 (best 1358.08594), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=0-step=120.ckpt' as top 1\n",
            "Epoch 1:  94% 120/127 [01:43<00:06,  1.16it/s, loss=3.43, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 127/127 [01:48<00:00,  1.17it/s, loss=3.43, v_num=0]\n",
            "Epoch 1: 100% 127/127 [01:48<00:00,  1.17it/s, loss=3.43, v_num=0]Epoch 1, global step 240: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=1-step=240.ckpt' as top 1\n",
            "Epoch 2:  94% 120/127 [01:42<00:05,  1.17it/s, loss=3.25, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 127/127 [01:47<00:00,  1.19it/s, loss=3.25, v_num=0]\n",
            "Epoch 2: 100% 127/127 [01:47<00:00,  1.19it/s, loss=3.25, v_num=0]Epoch 2, global step 360: 'val/CER' was not in top 1\n",
            "Epoch 3:  94% 120/127 [01:39<00:05,  1.21it/s, loss=3.21, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 127/127 [01:43<00:00,  1.22it/s, loss=3.21, v_num=0]\n",
            "Epoch 3: 100% 127/127 [01:43<00:00,  1.22it/s, loss=3.21, v_num=0]Epoch 3, global step 480: 'val/CER' was not in top 1\n",
            "Epoch 4:  94% 120/127 [01:38<00:05,  1.22it/s, loss=3.19, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100% 127/127 [01:42<00:00,  1.24it/s, loss=3.19, v_num=0]\n",
            "Epoch 4: 100% 127/127 [01:42<00:00,  1.24it/s, loss=3.19, v_num=0]Epoch 4, global step 600: 'val/CER' was not in top 1\n",
            "Epoch 5:  94% 120/127 [01:38<00:05,  1.22it/s, loss=3.03, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100% 127/127 [01:43<00:00,  1.22it/s, loss=3.03, v_num=0]\n",
            "Epoch 5: 100% 127/127 [01:43<00:00,  1.22it/s, loss=3.03, v_num=0]Epoch 5, global step 720: 'val/CER' was not in top 1\n",
            "Epoch 6:  94% 120/127 [01:35<00:05,  1.25it/s, loss=2.99, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6: 100% 127/127 [01:40<00:00,  1.26it/s, loss=2.99, v_num=0]\n",
            "Epoch 6: 100% 127/127 [01:40<00:00,  1.26it/s, loss=2.99, v_num=0]Epoch 6, global step 840: 'val/CER' was not in top 1\n",
            "Epoch 7:  94% 120/127 [01:37<00:05,  1.23it/s, loss=2.91, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7: 100% 127/127 [01:42<00:00,  1.24it/s, loss=2.91, v_num=0]\n",
            "Epoch 7: 100% 127/127 [01:42<00:00,  1.24it/s, loss=2.91, v_num=0]Epoch 7, global step 960: 'val/CER' reached 99.97784 (best 99.97784), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=7-step=960.ckpt' as top 1\n",
            "Epoch 8:  94% 120/127 [01:40<00:05,  1.19it/s, loss=2.93, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8: 100% 127/127 [01:45<00:00,  1.21it/s, loss=2.93, v_num=0]\n",
            "Epoch 8: 100% 127/127 [01:45<00:00,  1.21it/s, loss=2.93, v_num=0]Epoch 8, global step 1080: 'val/CER' was not in top 1\n",
            "Epoch 9:  94% 120/127 [01:41<00:05,  1.19it/s, loss=2.69, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9: 100% 127/127 [01:46<00:00,  1.19it/s, loss=2.69, v_num=0]\n",
            "Epoch 9: 100% 127/127 [01:46<00:00,  1.19it/s, loss=2.69, v_num=0]Epoch 9, global step 1200: 'val/CER' reached 99.80062 (best 99.80062), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=9-step=1200.ckpt' as top 1\n",
            "Epoch 10:  94% 120/127 [01:40<00:05,  1.20it/s, loss=2.49, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10: 100% 127/127 [01:44<00:00,  1.21it/s, loss=2.49, v_num=0]\n",
            "Epoch 10: 100% 127/127 [01:44<00:00,  1.21it/s, loss=2.49, v_num=0]Epoch 10, global step 1320: 'val/CER' reached 95.99025 (best 95.99025), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=10-step=1320.ckpt' as top 1\n",
            "Epoch 11:  94% 120/127 [01:41<00:05,  1.19it/s, loss=2.32, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11: 100% 127/127 [01:47<00:00,  1.19it/s, loss=2.32, v_num=0]\n",
            "Epoch 11: 100% 127/127 [01:47<00:00,  1.19it/s, loss=2.32, v_num=0]Epoch 11, global step 1440: 'val/CER' reached 88.65751 (best 88.65751), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=11-step=1440.ckpt' as top 1\n",
            "Epoch 12:  94% 120/127 [01:39<00:05,  1.21it/s, loss=2.27, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12: 100% 127/127 [01:43<00:00,  1.22it/s, loss=2.27, v_num=0]\n",
            "Epoch 12: 100% 127/127 [01:43<00:00,  1.22it/s, loss=2.27, v_num=0]Epoch 12, global step 1560: 'val/CER' reached 82.25520 (best 82.25520), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=12-step=1560.ckpt' as top 1\n",
            "Epoch 13:  94% 120/127 [01:41<00:05,  1.18it/s, loss=2.04, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13: 100% 127/127 [01:46<00:00,  1.19it/s, loss=2.04, v_num=0]\n",
            "Epoch 13: 100% 127/127 [01:46<00:00,  1.19it/s, loss=2.04, v_num=0]Epoch 13, global step 1680: 'val/CER' reached 80.99247 (best 80.99247), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=13-step=1680.ckpt' as top 1\n",
            "Epoch 14:  94% 120/127 [01:42<00:05,  1.17it/s, loss=1.93, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14: 100% 127/127 [01:46<00:00,  1.19it/s, loss=1.93, v_num=0]\n",
            "Epoch 14: 100% 127/127 [01:46<00:00,  1.19it/s, loss=1.93, v_num=0]Epoch 14, global step 1800: 'val/CER' reached 71.73239 (best 71.73239), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=14-step=1800.ckpt' as top 1\n",
            "Epoch 15:  94% 120/127 [01:42<00:06,  1.17it/s, loss=1.84, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15: 100% 127/127 [01:48<00:00,  1.17it/s, loss=1.84, v_num=0]\n",
            "Epoch 15: 100% 127/127 [01:48<00:00,  1.17it/s, loss=1.84, v_num=0]Epoch 15, global step 1920: 'val/CER' reached 71.04564 (best 71.04564), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=15-step=1920.ckpt' as top 1\n",
            "Epoch 16:  94% 120/127 [01:42<00:05,  1.17it/s, loss=1.82, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16: 100% 127/127 [01:46<00:00,  1.19it/s, loss=1.82, v_num=0]\n",
            "Epoch 16: 100% 127/127 [01:46<00:00,  1.19it/s, loss=1.82, v_num=0]Epoch 16, global step 2040: 'val/CER' reached 68.43155 (best 68.43155), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=16-step=2040.ckpt' as top 1\n",
            "Epoch 17:  94% 120/127 [01:40<00:05,  1.19it/s, loss=1.65, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17: 100% 127/127 [01:46<00:00,  1.20it/s, loss=1.65, v_num=0]\n",
            "Epoch 17: 100% 127/127 [01:46<00:00,  1.20it/s, loss=1.65, v_num=0]Epoch 17, global step 2160: 'val/CER' reached 65.59592 (best 65.59592), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=17-step=2160.ckpt' as top 1\n",
            "Epoch 18:  94% 120/127 [01:40<00:05,  1.19it/s, loss=1.55, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 18: 100% 127/127 [01:45<00:00,  1.21it/s, loss=1.55, v_num=0]\n",
            "Epoch 18: 100% 127/127 [01:45<00:00,  1.21it/s, loss=1.55, v_num=0]Epoch 18, global step 2280: 'val/CER' reached 58.99424 (best 58.99424), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=18-step=2280.ckpt' as top 1\n",
            "Epoch 19:  94% 120/127 [01:42<00:05,  1.17it/s, loss=1.39, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19: 100% 127/127 [01:47<00:00,  1.18it/s, loss=1.39, v_num=0]\n",
            "Epoch 19: 100% 127/127 [01:47<00:00,  1.18it/s, loss=1.39, v_num=0]Epoch 19, global step 2400: 'val/CER' reached 39.67656 (best 39.67656), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=19-step=2400.ckpt' as top 1\n",
            "Epoch 20:  94% 120/127 [01:42<00:05,  1.17it/s, loss=1.26, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 20: 100% 127/127 [01:47<00:00,  1.19it/s, loss=1.26, v_num=0]\n",
            "Epoch 20: 100% 127/127 [01:47<00:00,  1.19it/s, loss=1.26, v_num=0]Epoch 20, global step 2520: 'val/CER' reached 38.98981 (best 38.98981), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=20-step=2520.ckpt' as top 1\n",
            "Epoch 21:  94% 120/127 [01:40<00:05,  1.19it/s, loss=1.24, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 21: 100% 127/127 [01:45<00:00,  1.20it/s, loss=1.24, v_num=0]\n",
            "Epoch 21: 100% 127/127 [01:45<00:00,  1.20it/s, loss=1.24, v_num=0]Epoch 21, global step 2640: 'val/CER' reached 33.16349 (best 33.16349), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=21-step=2640.ckpt' as top 1\n",
            "Epoch 22:  94% 120/127 [01:43<00:06,  1.16it/s, loss=1.22, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 22: 100% 127/127 [01:47<00:00,  1.18it/s, loss=1.22, v_num=0]\n",
            "Epoch 22: 100% 127/127 [01:47<00:00,  1.18it/s, loss=1.22, v_num=0]Epoch 22, global step 2760: 'val/CER' was not in top 1\n",
            "Epoch 23:  94% 120/127 [01:41<00:05,  1.18it/s, loss=1.16, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 23: 100% 127/127 [01:46<00:00,  1.19it/s, loss=1.16, v_num=0]\n",
            "Epoch 23: 100% 127/127 [01:46<00:00,  1.19it/s, loss=1.16, v_num=0]Epoch 23, global step 2880: 'val/CER' reached 31.30261 (best 31.30261), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=23-step=2880.ckpt' as top 1\n",
            "Epoch 24:  94% 120/127 [01:39<00:05,  1.21it/s, loss=1.11, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 24: 100% 127/127 [01:44<00:00,  1.21it/s, loss=1.11, v_num=0]\n",
            "Epoch 24: 100% 127/127 [01:44<00:00,  1.21it/s, loss=1.11, v_num=0]Epoch 24, global step 3000: 'val/CER' reached 30.72663 (best 30.72663), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=24-step=3000.ckpt' as top 1\n",
            "Epoch 25:  94% 120/127 [01:39<00:05,  1.20it/s, loss=1.09, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 25: 100% 127/127 [01:44<00:00,  1.22it/s, loss=1.09, v_num=0]\n",
            "Epoch 25: 100% 127/127 [01:44<00:00,  1.22it/s, loss=1.09, v_num=0]Epoch 25, global step 3120: 'val/CER' reached 29.68542 (best 29.68542), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=25-step=3120.ckpt' as top 1\n",
            "Epoch 26:  94% 120/127 [01:39<00:05,  1.20it/s, loss=1.04, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 26: 100% 127/127 [01:45<00:00,  1.21it/s, loss=1.04, v_num=0]\n",
            "Epoch 26: 100% 127/127 [01:45<00:00,  1.21it/s, loss=1.04, v_num=0]Epoch 26, global step 3240: 'val/CER' reached 29.28666 (best 29.28666), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=26-step=3240.ckpt' as top 1\n",
            "Epoch 27:  94% 120/127 [01:42<00:05,  1.17it/s, loss=1.07, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 27: 100% 127/127 [01:46<00:00,  1.19it/s, loss=1.07, v_num=0]\n",
            "Epoch 27: 100% 127/127 [01:46<00:00,  1.19it/s, loss=1.07, v_num=0]Epoch 27, global step 3360: 'val/CER' reached 28.75498 (best 28.75498), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=27-step=3360.ckpt' as top 1\n",
            "Epoch 28:  94% 120/127 [01:42<00:05,  1.17it/s, loss=1.04, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 28: 100% 127/127 [01:48<00:00,  1.17it/s, loss=1.04, v_num=0]\n",
            "Epoch 28: 100% 127/127 [01:48<00:00,  1.17it/s, loss=1.04, v_num=0]Epoch 28, global step 3480: 'val/CER' reached 28.51130 (best 28.51130), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=28-step=3480.ckpt' as top 1\n",
            "Epoch 29:  94% 120/127 [01:39<00:05,  1.20it/s, loss=1, v_num=0]   \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 29: 100% 127/127 [01:44<00:00,  1.22it/s, loss=1, v_num=0]\n",
            "Epoch 29: 100% 127/127 [01:44<00:00,  1.22it/s, loss=1, v_num=0]Epoch 29, global step 3600: 'val/CER' was not in top 1\n",
            "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "Epoch 29: 100% 127/127 [01:44<00:00,  1.21it/s, loss=1, v_num=0]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 7/7 [00:02<00:00,  2.87it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m Runningstage.validating \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    28.51129913330078    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.4842711687088013    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   10.190518379211426    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    16.83650779724121    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        val/loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9136650562286377    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:02<00:00,  2.85s/it]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   28.701101303100586    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.7722066640853882    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    8.061378479003906    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   18.867517471313477    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8999432921409607    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "{'val_metrics': [{'val/loss': 0.9136650562286377,\n",
            "                  'val/CER': 28.51129913330078,\n",
            "                  'val/IER': 10.190518379211426,\n",
            "                  'val/DER': 1.4842711687088013,\n",
            "                  'val/SER': 16.83650779724121}],\n",
            " 'test_metrics': [{'test/loss': 0.8999432921409607,\n",
            "                   'test/CER': 28.701101303100586,\n",
            "                   'test/IER': 8.061378479003906,\n",
            "                   'test/DER': 1.7722066640853882,\n",
            "                   'test/SER': 18.867517471313477}],\n",
            " 'best_checkpoint': '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/16-14-48/checkpoints/epoch=28-step=3480.ckpt'}\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=tds_conv_ctc \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UwCjfpqYMX5",
        "outputId": "eb970e80-54cd-4757-cffc-faf45f04d725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-03-15 01:39:47,546][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TransformerCTCModule\n",
            "  input_dim: 1056\n",
            "  d_model: 512\n",
            "  nhead: 8\n",
            "  num_layers: 6\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 8\n",
            "num_workers: 4\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-15 01:39:47,550][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TransformerCTCModule', 'input_dim': 1056, 'd_model': 512, 'nhead': 8, 'num_layers': 6}\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "[2025-03-15 01:39:48,030][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-39-47/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/usr/local/lib/python3.11/dist-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type                  | Params\n",
            "---------------------------------------------------\n",
            "0 | model    | TransformerEncoderCTC | 19.5 M\n",
            "1 | ctc_loss | CTCLoss               | 0     \n",
            "2 | metrics  | ModuleDict            | 0     \n",
            "---------------------------------------------------\n",
            "19.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "19.5 M    Total params\n",
            "78.025    Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 0:  95% 480/507 [02:15<00:07,  3.54it/s, loss=-53.1, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  99% 500/507 [02:18<00:01,  3.60it/s, loss=-53.1, v_num=0]\n",
            "Epoch 0: 100% 507/507 [02:19<00:00,  3.63it/s, loss=-53.1, v_num=0]\n",
            "Epoch 0: 100% 507/507 [02:19<00:00,  3.63it/s, loss=-53.1, v_num=0]Epoch 0, global step 480: 'val/CER' reached 99.40186 (best 99.40186), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-39-47/checkpoints/epoch=0-step=480.ckpt' as top 1\n",
            "Epoch 1:  95% 480/507 [02:13<00:07,  3.61it/s, loss=1.38, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  99% 500/507 [02:16<00:01,  3.66it/s, loss=1.38, v_num=0]\n",
            "Epoch 1: 100% 507/507 [02:17<00:00,  3.69it/s, loss=1.38, v_num=0]\n",
            "Epoch 1: 100% 507/507 [02:17<00:00,  3.69it/s, loss=1.38, v_num=0]Epoch 1, global step 960: 'val/CER' was not in top 1\n",
            "Epoch 2:  95% 480/507 [02:10<00:07,  3.67it/s, loss=2.56, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  99% 500/507 [02:15<00:01,  3.70it/s, loss=2.56, v_num=0]\n",
            "Epoch 2: 100% 507/507 [02:15<00:00,  3.73it/s, loss=2.56, v_num=0]\n",
            "Epoch 2: 100% 507/507 [02:15<00:00,  3.73it/s, loss=2.56, v_num=0]Epoch 2, global step 1440: 'val/CER' was not in top 1\n",
            "Epoch 3:  79% 400/507 [01:49<00:29,  3.67it/s, loss=3.11, v_num=0]/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 27/27 [00:03<00:00,  7.68it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m Runningstage.validating \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    99.40186309814453    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    8.307487487792969    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    50.44306564331055    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    40.65130615234375    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        val/loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -47.70506286621094    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0:   0% 0/1 [00:00<?, ?it/s]Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'model=transformer_encoder_ctc']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/train.py\", line 117, in main\n",
            "    test_metrics = trainer.test(module, datamodule)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 780, in test\n",
            "    return call._call_and_handle_interrupt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 829, in _test_impl\n",
            "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1174, in _run_stage\n",
            "    return self._run_evaluate()\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1214, in _run_evaluate\n",
            "    eval_loop_results = self._evaluation_loop.run()\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 152, in advance\n",
            "    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 137, in advance\n",
            "    output = self._evaluation_step(**kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 234, in _evaluation_step\n",
            "    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1480, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/strategies/strategy.py\", line 399, in test_step\n",
            "    return self.model.test_step(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/lightning.py\", line 924, in test_step\n",
            "    return self._step(\"test\", *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/lightning.py\", line 878, in _step\n",
            "    emissions = self.forward(inputs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/lightning.py\", line 867, in forward\n",
            "    return self.model(inputs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/modules.py\", line 364, in forward\n",
            "    x = self.pos_encoder(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/modules.py\", line 380, in forward\n",
            "    x = x + self.pe[:x.size(0), :]\n",
            "        ~~^~~~~~~~~~~~~~~~~~~~~~~~\n",
            "RuntimeError: The size of tensor a (140757) must match the size of tensor b (5000) at non-singleton dimension 0\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "Epoch 3:  79% 400/507 [02:14<00:35,  2.97it/s, loss=3.11, v_num=0]\n",
            "Testing DataLoader 0:   0% 0/1 [00:01<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!git stash\n",
        "!git checkout b068bed\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=transformer_encoder_ctc \\\n",
        "  # --multirun\n",
        "!git checkout main\n",
        "!git stash pop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx91PF7kYMX5",
        "outputId": "ef000f5d-56bf-4db0-d51e-be766b36dcd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-14 22:08:07,035][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transformer_dim:\n",
            "  _target_: emg2qwerty.transforms.TransformerDim\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test:\n",
            "  - ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSGRUCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  hidden_size: 256\n",
            "  num_layers: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-14 22:08:07,039][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSGRUCTCModule', 'in_features': 528, 'mlp_features': [384], 'hidden_size': 256, 'num_layers': 32}\n",
            "[2025-03-14 22:08:07,326][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/drive/MyDrive/emg2qwerty/logs/2025-03-14/22-08-06/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/usr/local/lib/python3.11/dist-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 13.7 M\n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "13.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "13.7 M    Total params\n",
            "54.820    Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 0:  94% 120/127 [02:42<00:09,  1.35s/it, loss=171, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 127/127 [02:48<00:00,  1.33s/it, loss=171, v_num=0]\n",
            "Epoch 0: 100% 127/127 [02:48<00:00,  1.33s/it, loss=171, v_num=0]Epoch 0, global step 120: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/22-08-06/checkpoints/epoch=0-step=120.ckpt' as top 1\n",
            "Epoch 1:  94% 120/127 [02:41<00:09,  1.35s/it, loss=3.89, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 127/127 [02:49<00:00,  1.33s/it, loss=3.89, v_num=0]\n",
            "Epoch 1: 100% 127/127 [02:49<00:00,  1.33s/it, loss=3.89, v_num=0]Epoch 1, global step 240: 'val/CER' was not in top 1\n",
            "Epoch 2:  94% 120/127 [02:38<00:09,  1.32s/it, loss=3.54, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 127/127 [02:44<00:00,  1.29s/it, loss=3.54, v_num=0]\n",
            "Epoch 2: 100% 127/127 [02:44<00:00,  1.29s/it, loss=3.54, v_num=0]Epoch 2, global step 360: 'val/CER' was not in top 1\n",
            "Epoch 3:  94% 120/127 [02:37<00:09,  1.31s/it, loss=3.45, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 127/127 [02:43<00:00,  1.28s/it, loss=3.45, v_num=0]\n",
            "Epoch 3: 100% 127/127 [02:43<00:00,  1.28s/it, loss=3.45, v_num=0]Epoch 3, global step 480: 'val/CER' was not in top 1\n",
            "Epoch 4:  63% 80/127 [01:50<01:05,  1.39s/it, loss=3.45, v_num=0]/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation: 0it [00:00, ?it/s]^C\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=gru_ctc \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edc9xftLYMX5",
        "outputId": "e7b5de46-fda4-4ebc-964a-22f821e94893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-14 20:06:34,237][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSCNNGRUCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "  cnn_first: true\n",
            "  hidden_size: 256\n",
            "  num_layers: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-14 20:06:34,241][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSCNNGRUCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32, 'cnn_first': True, 'hidden_size': 256, 'num_layers': 32}\n",
            "[2025-03-14 20:06:34,592][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/drive/MyDrive/emg2qwerty/logs/2025-03-14/20-06-34/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/usr/local/lib/python3.11/dist-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 18.5 M\n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "18.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "18.5 M    Total params\n",
            "74.064    Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Epoch 0:  94% 120/127 [02:53<00:10,  1.45s/it, loss=130, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 127/127 [03:00<00:00,  1.42s/it, loss=130, v_num=0]\n",
            "Epoch 0: 100% 127/127 [03:00<00:00,  1.42s/it, loss=130, v_num=0]Epoch 0, global step 120: 'val/CER' reached 100.06646 (best 100.06646), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/20-06-34/checkpoints/epoch=0-step=120.ckpt' as top 1\n",
            "Epoch 1:  94% 120/127 [03:26<00:12,  1.72s/it, loss=3.55, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 127/127 [03:32<00:00,  1.68s/it, loss=3.55, v_num=0]\n",
            "Epoch 1: 100% 127/127 [03:32<00:00,  1.68s/it, loss=3.55, v_num=0]Epoch 1, global step 240: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/20-06-34/checkpoints/epoch=1-step=240.ckpt' as top 1\n",
            "Epoch 2:  94% 120/127 [03:28<00:12,  1.73s/it, loss=3.35, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 127/127 [03:37<00:00,  1.71s/it, loss=3.35, v_num=0]\n",
            "Epoch 2: 100% 127/127 [03:37<00:00,  1.71s/it, loss=3.35, v_num=0]Epoch 2, global step 360: 'val/CER' was not in top 1\n",
            "Epoch 3:  94% 120/127 [03:24<00:11,  1.71s/it, loss=3.4, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 127/127 [03:32<00:00,  1.67s/it, loss=3.4, v_num=0]\n",
            "Epoch 3: 100% 127/127 [03:32<00:00,  1.67s/it, loss=3.4, v_num=0]Epoch 3, global step 480: 'val/CER' was not in top 1\n",
            "Epoch 4:  94% 120/127 [03:29<00:12,  1.74s/it, loss=3.35, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100% 127/127 [03:34<00:00,  1.69s/it, loss=3.35, v_num=0]\n",
            "Epoch 4: 100% 127/127 [03:34<00:00,  1.69s/it, loss=3.35, v_num=0]Epoch 4, global step 600: 'val/CER' was not in top 1\n",
            "Epoch 5:  94% 120/127 [03:21<00:11,  1.68s/it, loss=3.43, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100% 127/127 [03:29<00:00,  1.65s/it, loss=3.43, v_num=0]\n",
            "Epoch 5: 100% 127/127 [03:29<00:00,  1.65s/it, loss=3.43, v_num=0]Epoch 5, global step 720: 'val/CER' was not in top 1\n",
            "Epoch 6:  94% 120/127 [03:23<00:11,  1.70s/it, loss=3.57, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6: 100% 127/127 [03:33<00:00,  1.68s/it, loss=3.57, v_num=0]\n",
            "Epoch 6: 100% 127/127 [03:33<00:00,  1.68s/it, loss=3.57, v_num=0]Epoch 6, global step 840: 'val/CER' was not in top 1\n",
            "Epoch 7:  94% 120/127 [03:18<00:11,  1.65s/it, loss=3.37, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7: 100% 127/127 [03:25<00:00,  1.62s/it, loss=3.37, v_num=0]\n",
            "Epoch 7: 100% 127/127 [03:25<00:00,  1.62s/it, loss=3.37, v_num=0]Epoch 7, global step 960: 'val/CER' was not in top 1\n",
            "Epoch 8:  94% 120/127 [03:22<00:11,  1.68s/it, loss=3.34, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8: 100% 127/127 [03:30<00:00,  1.66s/it, loss=3.34, v_num=0]\n",
            "Epoch 8: 100% 127/127 [03:30<00:00,  1.66s/it, loss=3.34, v_num=0]Epoch 8, global step 1080: 'val/CER' was not in top 1\n",
            "Epoch 9:  94% 120/127 [03:02<00:10,  1.52s/it, loss=3.43, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9: 100% 127/127 [03:08<00:00,  1.48s/it, loss=3.43, v_num=0]\n",
            "Epoch 9: 100% 127/127 [03:08<00:00,  1.48s/it, loss=3.43, v_num=0]Epoch 9, global step 1200: 'val/CER' was not in top 1\n",
            "Epoch 10:  94% 120/127 [02:48<00:09,  1.40s/it, loss=3.46, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10: 100% 127/127 [02:56<00:00,  1.39s/it, loss=3.46, v_num=0]\n",
            "Epoch 10: 100% 127/127 [02:56<00:00,  1.39s/it, loss=3.46, v_num=0]Epoch 10, global step 1320: 'val/CER' was not in top 1\n",
            "Epoch 11:  94% 120/127 [02:48<00:09,  1.40s/it, loss=3.5, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11: 100% 127/127 [02:54<00:00,  1.37s/it, loss=3.5, v_num=0]\n",
            "Epoch 11: 100% 127/127 [02:54<00:00,  1.37s/it, loss=3.5, v_num=0]Epoch 11, global step 1440: 'val/CER' was not in top 1\n",
            "Epoch 12:  94% 120/127 [02:54<00:10,  1.46s/it, loss=3.38, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12: 100% 127/127 [03:01<00:00,  1.43s/it, loss=3.38, v_num=0]\n",
            "Epoch 12: 100% 127/127 [03:01<00:00,  1.43s/it, loss=3.38, v_num=0]Epoch 12, global step 1560: 'val/CER' was not in top 1\n",
            "Epoch 13:  94% 120/127 [02:48<00:09,  1.40s/it, loss=3.51, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13: 100% 127/127 [02:53<00:00,  1.37s/it, loss=3.51, v_num=0]\n",
            "Epoch 13: 100% 127/127 [02:53<00:00,  1.37s/it, loss=3.51, v_num=0]Epoch 13, global step 1680: 'val/CER' was not in top 1\n",
            "Epoch 14:  94% 120/127 [02:48<00:09,  1.40s/it, loss=3.5, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14: 100% 127/127 [02:56<00:00,  1.39s/it, loss=3.5, v_num=0]\n",
            "Epoch 14: 100% 127/127 [02:56<00:00,  1.39s/it, loss=3.5, v_num=0]Epoch 14, global step 1800: 'val/CER' was not in top 1\n",
            "Epoch 15:  94% 120/127 [02:49<00:09,  1.41s/it, loss=3.39, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15: 100% 127/127 [02:54<00:00,  1.38s/it, loss=3.39, v_num=0]\n",
            "Epoch 15: 100% 127/127 [02:54<00:00,  1.38s/it, loss=3.39, v_num=0]Epoch 15, global step 1920: 'val/CER' was not in top 1\n",
            "Epoch 16:  94% 120/127 [02:48<00:09,  1.41s/it, loss=3.3, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16: 100% 127/127 [02:56<00:00,  1.39s/it, loss=3.3, v_num=0]\n",
            "Epoch 16: 100% 127/127 [02:56<00:00,  1.39s/it, loss=3.3, v_num=0]Epoch 16, global step 2040: 'val/CER' was not in top 1\n",
            "Epoch 17:  94% 120/127 [02:50<00:09,  1.42s/it, loss=3.36, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17: 100% 127/127 [02:56<00:00,  1.39s/it, loss=3.36, v_num=0]\n",
            "Epoch 17: 100% 127/127 [02:56<00:00,  1.39s/it, loss=3.36, v_num=0]Epoch 17, global step 2160: 'val/CER' was not in top 1\n",
            "Epoch 18:  94% 120/127 [02:55<00:10,  1.46s/it, loss=3.45, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 18: 100% 127/127 [03:00<00:00,  1.42s/it, loss=3.45, v_num=0]\n",
            "Epoch 18: 100% 127/127 [03:00<00:00,  1.42s/it, loss=3.45, v_num=0]Epoch 18, global step 2280: 'val/CER' was not in top 1\n",
            "Epoch 19:  94% 120/127 [03:01<00:10,  1.52s/it, loss=3.44, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19: 100% 127/127 [03:07<00:00,  1.48s/it, loss=3.44, v_num=0]\n",
            "Epoch 19: 100% 127/127 [03:07<00:00,  1.48s/it, loss=3.44, v_num=0]Epoch 19, global step 2400: 'val/CER' was not in top 1\n",
            "Epoch 20:  94% 120/127 [02:54<00:10,  1.45s/it, loss=3.37, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 20: 100% 127/127 [03:01<00:00,  1.43s/it, loss=3.37, v_num=0]\n",
            "Epoch 20: 100% 127/127 [03:01<00:00,  1.43s/it, loss=3.37, v_num=0]Epoch 20, global step 2520: 'val/CER' was not in top 1\n",
            "Epoch 21:  94% 120/127 [02:48<00:09,  1.40s/it, loss=3.39, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 21: 100% 127/127 [02:55<00:00,  1.38s/it, loss=3.39, v_num=0]\n",
            "Epoch 21: 100% 127/127 [02:55<00:00,  1.38s/it, loss=3.39, v_num=0]Epoch 21, global step 2640: 'val/CER' was not in top 1\n",
            "Epoch 22:  94% 120/127 [02:46<00:09,  1.38s/it, loss=3.41, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 22: 100% 127/127 [02:51<00:00,  1.35s/it, loss=3.41, v_num=0]\n",
            "Epoch 22: 100% 127/127 [02:51<00:00,  1.35s/it, loss=3.41, v_num=0]Epoch 22, global step 2760: 'val/CER' was not in top 1\n",
            "Epoch 23:  94% 120/127 [02:47<00:09,  1.40s/it, loss=3.41, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 23: 100% 127/127 [02:54<00:00,  1.37s/it, loss=3.41, v_num=0]\n",
            "Epoch 23: 100% 127/127 [02:54<00:00,  1.37s/it, loss=3.41, v_num=0]Epoch 23, global step 2880: 'val/CER' was not in top 1\n",
            "Epoch 24:  94% 120/127 [02:46<00:09,  1.39s/it, loss=3.33, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 24: 100% 127/127 [02:54<00:00,  1.37s/it, loss=3.33, v_num=0]\n",
            "Epoch 24: 100% 127/127 [02:54<00:00,  1.37s/it, loss=3.33, v_num=0]Epoch 24, global step 3000: 'val/CER' was not in top 1\n",
            "Epoch 25:  94% 120/127 [02:45<00:09,  1.38s/it, loss=3.38, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 25: 100% 127/127 [02:51<00:00,  1.35s/it, loss=3.38, v_num=0]\n",
            "Epoch 25: 100% 127/127 [02:51<00:00,  1.35s/it, loss=3.38, v_num=0]Epoch 25, global step 3120: 'val/CER' was not in top 1\n",
            "Epoch 26:  94% 120/127 [02:46<00:09,  1.39s/it, loss=3.33, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 26: 100% 127/127 [02:51<00:00,  1.35s/it, loss=3.33, v_num=0]\n",
            "Epoch 26: 100% 127/127 [02:51<00:00,  1.35s/it, loss=3.33, v_num=0]Epoch 26, global step 3240: 'val/CER' was not in top 1\n",
            "Epoch 27:  94% 120/127 [02:46<00:09,  1.39s/it, loss=3.35, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 27: 100% 127/127 [02:54<00:00,  1.37s/it, loss=3.35, v_num=0]\n",
            "Epoch 27: 100% 127/127 [02:54<00:00,  1.37s/it, loss=3.35, v_num=0]Epoch 27, global step 3360: 'val/CER' was not in top 1\n",
            "Epoch 28:  94% 120/127 [02:44<00:09,  1.37s/it, loss=3.42, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 28: 100% 127/127 [02:50<00:00,  1.34s/it, loss=3.42, v_num=0]\n",
            "Epoch 28: 100% 127/127 [02:50<00:00,  1.34s/it, loss=3.42, v_num=0]Epoch 28, global step 3480: 'val/CER' was not in top 1\n",
            "Epoch 29:  94% 120/127 [02:46<00:09,  1.38s/it, loss=3.31, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 29: 100% 127/127 [02:52<00:00,  1.36s/it, loss=3.31, v_num=0]\n",
            "Epoch 29: 100% 127/127 [02:52<00:00,  1.36s/it, loss=3.31, v_num=0]Epoch 29, global step 3600: 'val/CER' was not in top 1\n",
            "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "Epoch 29: 100% 127/127 [02:53<00:00,  1.37s/it, loss=3.31, v_num=0]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 7/7 [00:04<00:00,  1.67it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m Runningstage.validating \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          100.0          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          100.0          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        val/loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.509718894958496    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:47<00:00, 47.04s/it]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          100.0          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          100.0          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.191863775253296    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "{'val_metrics': [{'val/loss': 3.509718894958496,\n",
            "                  'val/CER': 100.0,\n",
            "                  'val/IER': 100.0,\n",
            "                  'val/DER': 0.0,\n",
            "                  'val/SER': 0.0}],\n",
            " 'test_metrics': [{'test/loss': 3.191863775253296,\n",
            "                   'test/CER': 100.0,\n",
            "                   'test/IER': 100.0,\n",
            "                   'test/DER': 0.0,\n",
            "                   'test/SER': 0.0}],\n",
            " 'best_checkpoint': '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/20-06-34/checkpoints/epoch=1-step=240.ckpt'}\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=cnn_gru_ctc \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8BnJ5D3YMX5",
        "outputId": "2bfdf498-c12c-447f-aa6e-84c2e4c2be52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-14 21:42:02,789][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSLSTMCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  hidden_size: 128\n",
            "  num_layers: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-14 21:42:02,804][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSLSTMCTCModule', 'in_features': 528, 'mlp_features': [384], 'hidden_size': 128, 'num_layers': 32}\n",
            "[2025-03-14 21:42:03,056][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/drive/MyDrive/emg2qwerty/logs/2025-03-14/21-42-02/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/usr/local/lib/python3.11/dist-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 5.1 M \n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "5.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "5.1 M     Total params\n",
            "20.545    Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 0:  94% 120/127 [01:43<00:06,  1.16it/s, loss=172, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 127/127 [01:48<00:00,  1.17it/s, loss=172, v_num=0]\n",
            "Epoch 0: 100% 127/127 [01:48<00:00,  1.17it/s, loss=172, v_num=0]Epoch 0, global step 120: 'val/CER' reached 100.02216 (best 100.02216), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/21-42-02/checkpoints/epoch=0-step=120.ckpt' as top 1\n",
            "Epoch 1:  94% 120/127 [01:40<00:05,  1.19it/s, loss=3.84, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 127/127 [01:46<00:00,  1.19it/s, loss=3.84, v_num=0]\n",
            "Epoch 1: 100% 127/127 [01:46<00:00,  1.19it/s, loss=3.84, v_num=0]Epoch 1, global step 240: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/21-42-02/checkpoints/epoch=1-step=240.ckpt' as top 1\n",
            "Epoch 2:  94% 120/127 [01:41<00:05,  1.18it/s, loss=3.61, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 127/127 [01:46<00:00,  1.19it/s, loss=3.61, v_num=0]\n",
            "Epoch 2: 100% 127/127 [01:46<00:00,  1.19it/s, loss=3.61, v_num=0]Epoch 2, global step 360: 'val/CER' was not in top 1\n",
            "Epoch 3:  94% 120/127 [01:40<00:05,  1.19it/s, loss=3.55, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 127/127 [01:46<00:00,  1.19it/s, loss=3.55, v_num=0]\n",
            "Epoch 3: 100% 127/127 [01:46<00:00,  1.19it/s, loss=3.55, v_num=0]Epoch 3, global step 480: 'val/CER' was not in top 1\n",
            "Epoch 4:  31% 40/127 [00:35<01:17,  1.12it/s, loss=3.56, v_num=0]Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 645, in _fit_impl\n",
            "Exception in thread Thread-4 (_pin_memory_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1177, in _run_stage\n",
            "    self._run_train()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1200, in _run_train\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 267, in advance\n",
            "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 188, in advance\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
            "    do_one_step()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
            "    batch = next(data_fetcher)\n",
            "            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py\", line 184, in __next__\n",
            "    return self.fetching_function()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py\", line 265, in fetching_function\n",
            "    self._fetch_next_batch(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py\", line 280, in _fetch_next_batch\n",
            "    batch = next(iterator)\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/supporters.py\", line 568, in __next__\n",
            "    fd = df.detach()\n",
            "         ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 519, in Client\n",
            "    c = SocketClient(address)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 647, in SocketClient\n",
            "    return self.request_next_batch(self.loader_iters)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/supporters.py\", line 580, in request_next_batch\n",
            "    return apply_to_collection(loader_iters, Iterator, next)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning_utilities/core/apply_func.py\", line 66, in apply_to_collection\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "    return function(data, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1285, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "                    ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/queue.py\", line 180, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 331, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/train.py\", line 129, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "           ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hydra/_internal/hydra.py\", line 119, in run\n",
            "    ret = run_job(\n",
            "          ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/train.py\", line 107, in main\n",
            "    trainer.fit(module, datamodule, ckpt_path=resume_from_checkpoint)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 603, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\", line 48, in _call_and_handle_interrupt\n",
            "    rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning_utilities/core/rank_zero.py\", line 42, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning_utilities/core/rank_zero.py\", line 79, in rank_zero_warn\n",
            "    _warn(message, stacklevel=stacklevel, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lightning_utilities/core/rank_zero.py\", line 73, in _warn\n",
            "    warnings.warn(message, stacklevel=stacklevel, **kwargs)\n",
            "  File \"/usr/lib/python3.11/warnings.py\", line 113, in _showwarnmsg\n",
            "    _showwarnmsg_impl(msg)\n",
            "  File \"/usr/lib/python3.11/warnings.py\", line 28, in _showwarnmsg_impl\n",
            "    text = _formatwarnmsg(msg)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/warnings.py\", line 129, in _formatwarnmsg\n",
            "    return _formatwarnmsg_impl(msg)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/warnings.py\", line 42, in _formatwarnmsg_impl\n",
            "    line = linecache.getline(msg.filename, msg.lineno)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/tokenize.py\", line 398, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/tokenize.py\", line 367, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/tokenize.py\", line 325, in read_or_stop\n",
            "    return readline()\n",
            "           ^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=lstm_ctc \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_57zsh3dYMX5",
        "outputId": "65143547-ff2b-496f-ab4a-6c22e5735641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-03-15 00:11:17,818][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transformer_dim:\n",
            "  _target_: emg2qwerty.transforms.TransformerDim\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test:\n",
            "  - ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSCNNLSTMCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "  hidden_size: 256\n",
            "  num_layers: 64\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 2\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-15 00:11:17,831][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSCNNLSTMCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32, 'hidden_size': 256, 'num_layers': 64}\n",
            "[2025-03-15 00:11:18,296][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/drive/MyDrive/emg2qwerty/logs/2025-03-15/00-11-17/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/usr/local/lib/python3.11/dist-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 39.7 M\n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "39.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "39.7 M    Total params\n",
            "158.802   Total estimated model params size (MB)\n",
            "Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Epoch 0:  94% 120/127 [04:07<00:14,  2.06s/it, loss=141, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 127/127 [04:15<00:00,  2.01s/it, loss=141, v_num=0]\n",
            "Epoch 0: 100% 127/127 [04:15<00:00,  2.01s/it, loss=141, v_num=0]Epoch 0, global step 120: 'val/CER' reached 99.91138 (best 99.91138), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/00-11-17/checkpoints/epoch=0-step=120.ckpt' as top 1\n",
            "Epoch 1:  94% 120/127 [04:10<00:14,  2.09s/it, loss=3.7, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 127/127 [04:18<00:00,  2.04s/it, loss=3.7, v_num=0]\n",
            "Epoch 1: 100% 127/127 [04:18<00:00,  2.04s/it, loss=3.7, v_num=0]Epoch 1, global step 240: 'val/CER' was not in top 1\n",
            "Epoch 2:  94% 120/127 [04:03<00:14,  2.03s/it, loss=3.54, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 127/127 [04:10<00:00,  1.97s/it, loss=3.54, v_num=0]\n",
            "Epoch 2: 100% 127/127 [04:10<00:00,  1.97s/it, loss=3.54, v_num=0]Epoch 2, global step 360: 'val/CER' was not in top 1\n",
            "Epoch 3:  94% 120/127 [04:03<00:14,  2.03s/it, loss=3.64, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.64, v_num=0]\n",
            "Epoch 3: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.64, v_num=0]Epoch 3, global step 480: 'val/CER' was not in top 1\n",
            "Epoch 4:  94% 120/127 [04:04<00:14,  2.04s/it, loss=3.56, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.56, v_num=0]\n",
            "Epoch 4: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.56, v_num=0]Epoch 4, global step 600: 'val/CER' was not in top 1\n",
            "Epoch 5:  94% 120/127 [04:03<00:14,  2.03s/it, loss=3.43, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100% 127/127 [04:10<00:00,  1.97s/it, loss=3.43, v_num=0]\n",
            "Epoch 5: 100% 127/127 [04:10<00:00,  1.97s/it, loss=3.43, v_num=0]Epoch 5, global step 720: 'val/CER' was not in top 1\n",
            "Epoch 6:  94% 120/127 [04:03<00:14,  2.03s/it, loss=3.52, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.52, v_num=0]\n",
            "Epoch 6: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.52, v_num=0]Epoch 6, global step 840: 'val/CER' was not in top 1\n",
            "Epoch 7:  94% 120/127 [04:02<00:14,  2.02s/it, loss=3.31, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7: 100% 127/127 [04:10<00:00,  1.98s/it, loss=3.31, v_num=0]\n",
            "Epoch 7: 100% 127/127 [04:10<00:00,  1.98s/it, loss=3.31, v_num=0]Epoch 7, global step 960: 'val/CER' was not in top 1\n",
            "Epoch 8:  94% 120/127 [04:02<00:14,  2.02s/it, loss=3.39, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8: 100% 127/127 [04:09<00:00,  1.97s/it, loss=3.39, v_num=0]\n",
            "Epoch 8: 100% 127/127 [04:09<00:00,  1.97s/it, loss=3.39, v_num=0]Epoch 8, global step 1080: 'val/CER' was not in top 1\n",
            "Epoch 9:  94% 120/127 [04:04<00:14,  2.04s/it, loss=3.51, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.51, v_num=0]\n",
            "Epoch 9: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.51, v_num=0]Epoch 9, global step 1200: 'val/CER' was not in top 1\n",
            "Epoch 10:  94% 120/127 [04:04<00:14,  2.04s/it, loss=3.42, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10: 100% 127/127 [04:12<00:00,  1.99s/it, loss=3.42, v_num=0]\n",
            "Epoch 10: 100% 127/127 [04:12<00:00,  1.99s/it, loss=3.42, v_num=0]Epoch 10, global step 1320: 'val/CER' was not in top 1\n",
            "Epoch 11:  94% 120/127 [04:02<00:14,  2.02s/it, loss=3.46, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.46, v_num=0]\n",
            "Epoch 11: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.46, v_num=0]Epoch 11, global step 1440: 'val/CER' was not in top 1\n",
            "Epoch 12:  94% 120/127 [04:03<00:14,  2.03s/it, loss=3.58, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.58, v_num=0]\n",
            "Epoch 12: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.58, v_num=0]Epoch 12, global step 1560: 'val/CER' was not in top 1\n",
            "Epoch 13:  94% 120/127 [04:03<00:14,  2.03s/it, loss=3.43, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13: 100% 127/127 [04:10<00:00,  1.97s/it, loss=3.43, v_num=0]\n",
            "Epoch 13: 100% 127/127 [04:10<00:00,  1.97s/it, loss=3.43, v_num=0]Epoch 13, global step 1680: 'val/CER' was not in top 1\n",
            "Epoch 14:  94% 120/127 [04:03<00:14,  2.03s/it, loss=3.38, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14: 100% 127/127 [04:10<00:00,  1.97s/it, loss=3.38, v_num=0]\n",
            "Epoch 14: 100% 127/127 [04:10<00:00,  1.97s/it, loss=3.38, v_num=0]Epoch 14, global step 1800: 'val/CER' was not in top 1\n",
            "Epoch 15:  94% 120/127 [04:02<00:14,  2.02s/it, loss=3.32, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15: 100% 127/127 [04:10<00:00,  1.97s/it, loss=3.32, v_num=0]\n",
            "Epoch 15: 100% 127/127 [04:10<00:00,  1.97s/it, loss=3.32, v_num=0]Epoch 15, global step 1920: 'val/CER' was not in top 1\n",
            "Epoch 16:  94% 120/127 [04:02<00:14,  2.02s/it, loss=3.37, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.37, v_num=0]\n",
            "Epoch 16: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.37, v_num=0]Epoch 16, global step 2040: 'val/CER' was not in top 1\n",
            "Epoch 17:  94% 120/127 [04:02<00:14,  2.02s/it, loss=3.33, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.33, v_num=0]\n",
            "Epoch 17: 100% 127/127 [04:11<00:00,  1.98s/it, loss=3.33, v_num=0]Epoch 17, global step 2160: 'val/CER' was not in top 1\n",
            "Epoch 18:  79% 100/127 [03:22<00:54,  2.03s/it, loss=3.4, v_num=0] /usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 7/7 [00:05<00:00,  1.37it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m Runningstage.validating \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    99.91138458251953    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.022153301164507866   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    95.32565307617188    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4.56358003616333     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        val/loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   113.75914764404297    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 0it [00:00, ?it/s]Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'model=cnn_lstm_ctc']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/train.py\", line 117, in main\n",
            "    test_metrics = trainer.test(module, datamodule)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 780, in test\n",
            "    return call._call_and_handle_interrupt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 829, in _test_impl\n",
            "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1174, in _run_stage\n",
            "    return self._run_evaluate()\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1214, in _run_evaluate\n",
            "    eval_loop_results = self._evaluation_loop.run()\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 152, in advance\n",
            "    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 121, in advance\n",
            "    batch = next(data_fetcher)\n",
            "            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py\", line 184, in __next__\n",
            "    return self.fetching_function()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py\", line 265, in fetching_function\n",
            "    self._fetch_next_batch(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py\", line 280, in _fetch_next_batch\n",
            "    batch = next(iterator)\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1346, in _next_data\n",
            "    return self._process_data(data)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1372, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_utils.py\", line 705, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "            ~~~~~~~~~~~~^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 348, in __getitem__\n",
            "    return self.datasets[dataset_idx][sample_idx]\n",
            "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/data.py\", line 500, in __getitem__\n",
            "    emg = self.transform(window)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/transforms.py\", line 102, in __call__\n",
            "    data = transform(data)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "TypeError: 'list' object is not callable\n",
            "\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "Epoch 18:  79% 100/127 [03:49<01:01,  2.29s/it, loss=3.4, v_num=0]\n",
            "Testing: 0it [00:03, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=cnn_lstm_ctc \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEaMNsZncSu8",
        "outputId": "39cf1e15-013c-4e9a-c126-a74af52af09b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-03-14 23:20:39,172][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transformer_dim:\n",
            "  _target_: emg2qwerty.transforms.TransformerDim\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test:\n",
            "  - ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 2\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-14 23:20:39,186][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-14 23:20:39,412][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/usr/local/lib/python3.11/dist-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 5.3 M \n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "5.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "5.3 M     Total params\n",
            "21.173    Total estimated model params size (MB)\n",
            "Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Epoch 0:  94% 120/127 [01:54<00:06,  1.04it/s, loss=116, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 127/127 [02:00<00:00,  1.06it/s, loss=116, v_num=0]\n",
            "Epoch 0: 100% 127/127 [02:00<00:00,  1.06it/s, loss=116, v_num=0]Epoch 0, global step 120: 'val/CER' reached 1352.45898 (best 1352.45898), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=0-step=120.ckpt' as top 1\n",
            "Epoch 1:  94% 120/127 [01:45<00:06,  1.14it/s, loss=3.5, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 127/127 [01:50<00:00,  1.15it/s, loss=3.5, v_num=0]\n",
            "Epoch 1: 100% 127/127 [01:50<00:00,  1.15it/s, loss=3.5, v_num=0]Epoch 1, global step 240: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=1-step=240.ckpt' as top 1\n",
            "Epoch 2:  94% 120/127 [01:43<00:06,  1.16it/s, loss=3.27, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 127/127 [01:47<00:00,  1.18it/s, loss=3.27, v_num=0]\n",
            "Epoch 2: 100% 127/127 [01:47<00:00,  1.18it/s, loss=3.27, v_num=0]Epoch 2, global step 360: 'val/CER' was not in top 1\n",
            "Epoch 3:  94% 120/127 [01:43<00:06,  1.15it/s, loss=3.25, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 127/127 [01:48<00:00,  1.17it/s, loss=3.25, v_num=0]\n",
            "Epoch 3: 100% 127/127 [01:48<00:00,  1.17it/s, loss=3.25, v_num=0]Epoch 3, global step 480: 'val/CER' was not in top 1\n",
            "Epoch 4:  94% 120/127 [01:40<00:05,  1.19it/s, loss=3.2, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100% 127/127 [01:45<00:00,  1.20it/s, loss=3.2, v_num=0]\n",
            "Epoch 4: 100% 127/127 [01:45<00:00,  1.20it/s, loss=3.2, v_num=0]Epoch 4, global step 600: 'val/CER' was not in top 1\n",
            "Epoch 5:  94% 120/127 [01:39<00:05,  1.20it/s, loss=3.03, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100% 127/127 [01:44<00:00,  1.22it/s, loss=3.03, v_num=0]\n",
            "Epoch 5: 100% 127/127 [01:44<00:00,  1.22it/s, loss=3.03, v_num=0]Epoch 5, global step 720: 'val/CER' was not in top 1\n",
            "Epoch 6:  94% 120/127 [01:35<00:05,  1.25it/s, loss=3, v_num=0]   \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6: 100% 127/127 [01:40<00:00,  1.27it/s, loss=3, v_num=0]\n",
            "Epoch 6: 100% 127/127 [01:40<00:00,  1.27it/s, loss=3, v_num=0]Epoch 6, global step 840: 'val/CER' was not in top 1\n",
            "Epoch 7:  94% 120/127 [01:37<00:05,  1.23it/s, loss=2.9, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7: 100% 127/127 [01:43<00:00,  1.23it/s, loss=2.9, v_num=0]\n",
            "Epoch 7: 100% 127/127 [01:43<00:00,  1.23it/s, loss=2.9, v_num=0]Epoch 7, global step 960: 'val/CER' was not in top 1\n",
            "Epoch 8:  94% 120/127 [01:34<00:05,  1.27it/s, loss=2.91, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8: 100% 127/127 [01:38<00:00,  1.29it/s, loss=2.91, v_num=0]\n",
            "Epoch 8: 100% 127/127 [01:38<00:00,  1.29it/s, loss=2.91, v_num=0]Epoch 8, global step 1080: 'val/CER' was not in top 1\n",
            "Epoch 9:  94% 120/127 [01:34<00:05,  1.27it/s, loss=2.75, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9: 100% 127/127 [01:37<00:00,  1.30it/s, loss=2.75, v_num=0]\n",
            "Epoch 9: 100% 127/127 [01:37<00:00,  1.30it/s, loss=2.75, v_num=0]Epoch 9, global step 1200: 'val/CER' reached 99.97784 (best 99.97784), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=9-step=1200.ckpt' as top 1\n",
            "Epoch 10:  94% 120/127 [01:30<00:05,  1.33it/s, loss=2.53, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10: 100% 127/127 [01:34<00:00,  1.34it/s, loss=2.53, v_num=0]\n",
            "Epoch 10: 100% 127/127 [01:34<00:00,  1.34it/s, loss=2.53, v_num=0]Epoch 10, global step 1320: 'val/CER' reached 94.92690 (best 94.92690), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=10-step=1320.ckpt' as top 1\n",
            "Epoch 11:  94% 120/127 [01:31<00:05,  1.32it/s, loss=2.31, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11: 100% 127/127 [01:34<00:00,  1.34it/s, loss=2.31, v_num=0]\n",
            "Epoch 11: 100% 127/127 [01:34<00:00,  1.34it/s, loss=2.31, v_num=0]Epoch 11, global step 1440: 'val/CER' reached 88.21445 (best 88.21445), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=11-step=1440.ckpt' as top 1\n",
            "Epoch 12:  94% 120/127 [01:32<00:05,  1.30it/s, loss=2.26, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12: 100% 127/127 [01:36<00:00,  1.32it/s, loss=2.26, v_num=0]\n",
            "Epoch 12: 100% 127/127 [01:36<00:00,  1.32it/s, loss=2.26, v_num=0]Epoch 12, global step 1560: 'val/CER' reached 85.88834 (best 85.88834), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=12-step=1560.ckpt' as top 1\n",
            "Epoch 13:  94% 120/127 [01:31<00:05,  1.31it/s, loss=2.04, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13: 100% 127/127 [01:36<00:00,  1.32it/s, loss=2.04, v_num=0]\n",
            "Epoch 13: 100% 127/127 [01:36<00:00,  1.32it/s, loss=2.04, v_num=0]Epoch 13, global step 1680: 'val/CER' reached 80.97031 (best 80.97031), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=13-step=1680.ckpt' as top 1\n",
            "Epoch 14:  94% 120/127 [01:31<00:05,  1.31it/s, loss=1.95, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.95, v_num=0]\n",
            "Epoch 14: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.95, v_num=0]Epoch 14, global step 1800: 'val/CER' reached 71.79885 (best 71.79885), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=14-step=1800.ckpt' as top 1\n",
            "Epoch 15:  94% 120/127 [01:29<00:05,  1.35it/s, loss=1.85, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15: 100% 127/127 [01:32<00:00,  1.37it/s, loss=1.85, v_num=0]\n",
            "Epoch 15: 100% 127/127 [01:32<00:00,  1.37it/s, loss=1.85, v_num=0]Epoch 15, global step 1920: 'val/CER' was not in top 1\n",
            "Epoch 16:  94% 120/127 [01:29<00:05,  1.34it/s, loss=1.79, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16: 100% 127/127 [01:33<00:00,  1.35it/s, loss=1.79, v_num=0]\n",
            "Epoch 16: 100% 127/127 [01:33<00:00,  1.35it/s, loss=1.79, v_num=0]Epoch 16, global step 2040: 'val/CER' reached 67.96632 (best 67.96632), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=16-step=2040.ckpt' as top 1\n",
            "Epoch 17:  94% 120/127 [01:30<00:05,  1.32it/s, loss=1.64, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.64, v_num=0]\n",
            "Epoch 17: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.64, v_num=0]Epoch 17, global step 2160: 'val/CER' reached 62.71600 (best 62.71600), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=17-step=2160.ckpt' as top 1\n",
            "Epoch 18:  94% 120/127 [01:30<00:05,  1.33it/s, loss=1.57, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 18: 100% 127/127 [01:34<00:00,  1.35it/s, loss=1.57, v_num=0]\n",
            "Epoch 18: 100% 127/127 [01:34<00:00,  1.35it/s, loss=1.57, v_num=0]Epoch 18, global step 2280: 'val/CER' reached 54.09836 (best 54.09836), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=18-step=2280.ckpt' as top 1\n",
            "Epoch 19:  94% 120/127 [01:31<00:05,  1.30it/s, loss=1.43, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.43, v_num=0]\n",
            "Epoch 19: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.43, v_num=0]Epoch 19, global step 2400: 'val/CER' reached 44.06292 (best 44.06292), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=19-step=2400.ckpt' as top 1\n",
            "Epoch 20:  94% 120/127 [01:33<00:05,  1.29it/s, loss=1.32, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 20: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.32, v_num=0]\n",
            "Epoch 20: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.32, v_num=0]Epoch 20, global step 2520: 'val/CER' reached 41.00576 (best 41.00576), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=20-step=2520.ckpt' as top 1\n",
            "Epoch 21:  94% 120/127 [01:30<00:05,  1.33it/s, loss=1.26, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 21: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.26, v_num=0]\n",
            "Epoch 21: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.26, v_num=0]Epoch 21, global step 2640: 'val/CER' reached 36.44218 (best 36.44218), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=21-step=2640.ckpt' as top 1\n",
            "Epoch 22:  94% 120/127 [01:30<00:05,  1.33it/s, loss=1.23, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 22: 100% 127/127 [01:33<00:00,  1.35it/s, loss=1.23, v_num=0]\n",
            "Epoch 22: 100% 127/127 [01:33<00:00,  1.35it/s, loss=1.23, v_num=0]Epoch 22, global step 2760: 'val/CER' reached 35.09083 (best 35.09083), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=22-step=2760.ckpt' as top 1\n",
            "Epoch 23:  94% 120/127 [01:33<00:05,  1.29it/s, loss=1.18, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 23: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.18, v_num=0]\n",
            "Epoch 23: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.18, v_num=0]Epoch 23, global step 2880: 'val/CER' reached 32.54320 (best 32.54320), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=23-step=2880.ckpt' as top 1\n",
            "Epoch 24:  94% 120/127 [01:32<00:05,  1.29it/s, loss=1.15, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 24: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.15, v_num=0]\n",
            "Epoch 24: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.15, v_num=0]Epoch 24, global step 3000: 'val/CER' reached 32.29951 (best 32.29951), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=24-step=3000.ckpt' as top 1\n",
            "Epoch 25:  94% 120/127 [01:31<00:05,  1.31it/s, loss=1.14, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 25: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.14, v_num=0]\n",
            "Epoch 25: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.14, v_num=0]Epoch 25, global step 3120: 'val/CER' was not in top 1\n",
            "Epoch 26:  94% 120/127 [01:29<00:05,  1.34it/s, loss=1.1, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 26: 100% 127/127 [01:33<00:00,  1.36it/s, loss=1.1, v_num=0]\n",
            "Epoch 26: 100% 127/127 [01:33<00:00,  1.36it/s, loss=1.1, v_num=0]Epoch 26, global step 3240: 'val/CER' reached 31.78999 (best 31.78999), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=26-step=3240.ckpt' as top 1\n",
            "Epoch 27:  94% 120/127 [01:32<00:05,  1.29it/s, loss=1.08, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 27: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.08, v_num=0]\n",
            "Epoch 27: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.08, v_num=0]Epoch 27, global step 3360: 'val/CER' reached 30.66017 (best 30.66017), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-14/23-20-39/checkpoints/epoch=27-step=3360.ckpt' as top 1\n",
            "Epoch 28:  94% 120/127 [01:33<00:05,  1.29it/s, loss=1.08, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 28: 100% 127/127 [01:37<00:00,  1.31it/s, loss=1.08, v_num=0]\n",
            "Epoch 28: 100% 127/127 [01:37<00:00,  1.31it/s, loss=1.08, v_num=0]Epoch 28, global step 3480: 'val/CER' was not in top 1\n",
            "Epoch 29:  94% 120/127 [01:30<00:05,  1.32it/s, loss=1.04, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 29: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.04, v_num=0]\n",
            "Epoch 29: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.04, v_num=0]Epoch 29, global step 3600: 'val/CER' was not in top 1\n",
            "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "Epoch 29: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.04, v_num=0]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 7/7 [00:03<00:00,  2.27it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m Runningstage.validating \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   30.660167694091797    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.794417381286621    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   11.962782859802246    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   16.902969360351562    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        val/loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9807783961296082    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 0it [00:00, ?it/s]Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'model=tds_conv_ctc']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/train.py\", line 117, in main\n",
            "    test_metrics = trainer.test(module, datamodule)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 780, in test\n",
            "    return call._call_and_handle_interrupt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 829, in _test_impl\n",
            "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1174, in _run_stage\n",
            "    return self._run_evaluate()\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1214, in _run_evaluate\n",
            "    eval_loop_results = self._evaluation_loop.run()\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 152, in advance\n",
            "    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 121, in advance\n",
            "    batch = next(data_fetcher)\n",
            "            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py\", line 184, in __next__\n",
            "    return self.fetching_function()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py\", line 265, in fetching_function\n",
            "    self._fetch_next_batch(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/fetching.py\", line 280, in _fetch_next_batch\n",
            "    batch = next(iterator)\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1346, in _next_data\n",
            "    return self._process_data(data)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1372, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_utils.py\", line 705, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "            ~~~~~~~~~~~~^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 348, in __getitem__\n",
            "    return self.datasets[dataset_idx][sample_idx]\n",
            "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/data.py\", line 500, in __getitem__\n",
            "    emg = self.transform(window)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/emg2qwerty/emg2qwerty/transforms.py\", line 102, in __call__\n",
            "    data = transform(data)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "TypeError: 'list' object is not callable\n",
            "\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "Testing: 0it [00:03, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=tds_conv_ctc \\\n",
        "  # decoder= ctc_beam\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=cnn_lstm_ctc\n",
        "  # --multirun"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubo61NH7dReq",
        "outputId": "a4c2b1be-f257-4e3a-d77d-fc031f38c2da"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-03-15 01:59:20,945][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 42\n",
            "batch_size: 32\n",
            "num_workers: 2\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 42\n",
            "[2025-03-15 01:59:20,959][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-15 01:59:21,303][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.11/dist-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/usr/local/lib/python3.11/dist-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 5.3 M \n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "5.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "5.3 M     Total params\n",
            "21.173    Total estimated model params size (MB)\n",
            "Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Epoch 0:  94% 120/127 [02:02<00:07,  1.02s/it, loss=122, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 127/127 [02:07<00:00,  1.00s/it, loss=122, v_num=0]\n",
            "Epoch 0: 100% 127/127 [02:07<00:00,  1.00s/it, loss=122, v_num=0]Epoch 0, global step 120: 'val/CER' reached 1347.38586 (best 1347.38586), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=0-step=120.ckpt' as top 1\n",
            "Epoch 1:  94% 120/127 [01:53<00:06,  1.05it/s, loss=3.46, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 127/127 [01:58<00:00,  1.07it/s, loss=3.46, v_num=0]\n",
            "Epoch 1: 100% 127/127 [01:58<00:00,  1.07it/s, loss=3.46, v_num=0]Epoch 1, global step 240: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=1-step=240.ckpt' as top 1\n",
            "Epoch 2:  94% 120/127 [01:50<00:06,  1.09it/s, loss=3.37, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 127/127 [01:54<00:00,  1.11it/s, loss=3.37, v_num=0]\n",
            "Epoch 2: 100% 127/127 [01:54<00:00,  1.11it/s, loss=3.37, v_num=0]Epoch 2, global step 360: 'val/CER' was not in top 1\n",
            "Epoch 3:  94% 120/127 [01:49<00:06,  1.10it/s, loss=3.24, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 127/127 [01:53<00:00,  1.12it/s, loss=3.24, v_num=0]\n",
            "Epoch 3: 100% 127/127 [01:53<00:00,  1.12it/s, loss=3.24, v_num=0]Epoch 3, global step 480: 'val/CER' was not in top 1\n",
            "Epoch 4:  94% 120/127 [01:48<00:06,  1.11it/s, loss=3.13, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100% 127/127 [01:52<00:00,  1.13it/s, loss=3.13, v_num=0]\n",
            "Epoch 4: 100% 127/127 [01:52<00:00,  1.13it/s, loss=3.13, v_num=0]Epoch 4, global step 600: 'val/CER' was not in top 1\n",
            "Epoch 5:  94% 120/127 [01:44<00:06,  1.15it/s, loss=3.11, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100% 127/127 [01:49<00:00,  1.16it/s, loss=3.11, v_num=0]\n",
            "Epoch 5: 100% 127/127 [01:49<00:00,  1.16it/s, loss=3.11, v_num=0]Epoch 5, global step 720: 'val/CER' was not in top 1\n",
            "Epoch 6:  94% 120/127 [01:37<00:05,  1.23it/s, loss=2.98, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6: 100% 127/127 [01:41<00:00,  1.25it/s, loss=2.98, v_num=0]\n",
            "Epoch 6: 100% 127/127 [01:41<00:00,  1.25it/s, loss=2.98, v_num=0]Epoch 6, global step 840: 'val/CER' was not in top 1\n",
            "Epoch 7:  94% 120/127 [01:38<00:05,  1.22it/s, loss=2.9, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7: 100% 127/127 [01:44<00:00,  1.22it/s, loss=2.9, v_num=0]\n",
            "Epoch 7: 100% 127/127 [01:44<00:00,  1.22it/s, loss=2.9, v_num=0]Epoch 7, global step 960: 'val/CER' reached 99.91138 (best 99.91138), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=7-step=960.ckpt' as top 1\n",
            "Epoch 8:  94% 120/127 [01:39<00:05,  1.21it/s, loss=2.7, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8: 100% 127/127 [01:43<00:00,  1.23it/s, loss=2.7, v_num=0]\n",
            "Epoch 8: 100% 127/127 [01:43<00:00,  1.23it/s, loss=2.7, v_num=0]Epoch 8, global step 1080: 'val/CER' reached 96.72131 (best 96.72131), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=8-step=1080.ckpt' as top 1\n",
            "Epoch 9:  94% 120/127 [01:36<00:05,  1.24it/s, loss=2.54, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9: 100% 127/127 [01:41<00:00,  1.25it/s, loss=2.54, v_num=0]\n",
            "Epoch 9: 100% 127/127 [01:41<00:00,  1.25it/s, loss=2.54, v_num=0]Epoch 9, global step 1200: 'val/CER' reached 91.47098 (best 91.47098), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=9-step=1200.ckpt' as top 1\n",
            "Epoch 10:  94% 120/127 [01:40<00:05,  1.19it/s, loss=2.38, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10: 100% 127/127 [01:45<00:00,  1.20it/s, loss=2.38, v_num=0]\n",
            "Epoch 10: 100% 127/127 [01:45<00:00,  1.20it/s, loss=2.38, v_num=0]Epoch 10, global step 1320: 'val/CER' reached 89.49934 (best 89.49934), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=10-step=1320.ckpt' as top 1\n",
            "Epoch 11:  94% 120/127 [01:36<00:05,  1.24it/s, loss=2.22, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11: 100% 127/127 [01:41<00:00,  1.25it/s, loss=2.22, v_num=0]\n",
            "Epoch 11: 100% 127/127 [01:41<00:00,  1.25it/s, loss=2.22, v_num=0]Epoch 11, global step 1440: 'val/CER' reached 88.67966 (best 88.67966), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=11-step=1440.ckpt' as top 1\n",
            "Epoch 12:  94% 120/127 [01:35<00:05,  1.26it/s, loss=2.11, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12: 100% 127/127 [01:38<00:00,  1.28it/s, loss=2.11, v_num=0]\n",
            "Epoch 12: 100% 127/127 [01:38<00:00,  1.28it/s, loss=2.11, v_num=0]Epoch 12, global step 1560: 'val/CER' reached 84.27116 (best 84.27116), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=12-step=1560.ckpt' as top 1\n",
            "Epoch 13:  94% 120/127 [01:32<00:05,  1.30it/s, loss=1.97, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.97, v_num=0]\n",
            "Epoch 13: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.97, v_num=0]Epoch 13, global step 1680: 'val/CER' was not in top 1\n",
            "Epoch 14:  94% 120/127 [01:31<00:05,  1.31it/s, loss=1.88, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14: 100% 127/127 [01:35<00:00,  1.34it/s, loss=1.88, v_num=0]\n",
            "Epoch 14: 100% 127/127 [01:35<00:00,  1.34it/s, loss=1.88, v_num=0]Epoch 14, global step 1800: 'val/CER' reached 82.60966 (best 82.60966), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=14-step=1800.ckpt' as top 1\n",
            "Epoch 15:  94% 120/127 [01:29<00:05,  1.34it/s, loss=1.73, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15: 100% 127/127 [01:33<00:00,  1.35it/s, loss=1.73, v_num=0]\n",
            "Epoch 15: 100% 127/127 [01:33<00:00,  1.35it/s, loss=1.73, v_num=0]Epoch 15, global step 1920: 'val/CER' reached 73.54896 (best 73.54896), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=15-step=1920.ckpt' as top 1\n",
            "Epoch 16:  94% 120/127 [01:29<00:05,  1.35it/s, loss=1.61, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16: 100% 127/127 [01:32<00:00,  1.37it/s, loss=1.61, v_num=0]\n",
            "Epoch 16: 100% 127/127 [01:32<00:00,  1.37it/s, loss=1.61, v_num=0]Epoch 16, global step 2040: 'val/CER' reached 53.87683 (best 53.87683), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=16-step=2040.ckpt' as top 1\n",
            "Epoch 17:  94% 120/127 [01:31<00:05,  1.32it/s, loss=1.48, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17: 100% 127/127 [01:34<00:00,  1.34it/s, loss=1.48, v_num=0]\n",
            "Epoch 17: 100% 127/127 [01:34<00:00,  1.34it/s, loss=1.48, v_num=0]Epoch 17, global step 2160: 'val/CER' reached 43.53123 (best 43.53123), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=17-step=2160.ckpt' as top 1\n",
            "Epoch 18:  94% 120/127 [01:31<00:05,  1.32it/s, loss=1.41, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 18: 100% 127/127 [01:34<00:00,  1.34it/s, loss=1.41, v_num=0]\n",
            "Epoch 18: 100% 127/127 [01:34<00:00,  1.34it/s, loss=1.41, v_num=0]Epoch 18, global step 2280: 'val/CER' was not in top 1\n",
            "Epoch 19:  94% 120/127 [01:30<00:05,  1.32it/s, loss=1.3, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.3, v_num=0]\n",
            "Epoch 19: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.3, v_num=0]Epoch 19, global step 2400: 'val/CER' reached 37.08463 (best 37.08463), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=19-step=2400.ckpt' as top 1\n",
            "Epoch 20:  94% 120/127 [01:30<00:05,  1.33it/s, loss=1.24, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 20: 100% 127/127 [01:34<00:00,  1.35it/s, loss=1.24, v_num=0]\n",
            "Epoch 20: 100% 127/127 [01:34<00:00,  1.35it/s, loss=1.24, v_num=0]Epoch 20, global step 2520: 'val/CER' was not in top 1\n",
            "Epoch 21:  94% 120/127 [01:29<00:05,  1.35it/s, loss=1.17, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 21: 100% 127/127 [01:32<00:00,  1.37it/s, loss=1.17, v_num=0]\n",
            "Epoch 21: 100% 127/127 [01:32<00:00,  1.37it/s, loss=1.17, v_num=0]Epoch 21, global step 2640: 'val/CER' reached 33.47364 (best 33.47364), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=21-step=2640.ckpt' as top 1\n",
            "Epoch 22:  94% 120/127 [01:32<00:05,  1.29it/s, loss=1.15, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 22: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.15, v_num=0]\n",
            "Epoch 22: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.15, v_num=0]Epoch 22, global step 2760: 'val/CER' reached 32.27736 (best 32.27736), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=22-step=2760.ckpt' as top 1\n",
            "Epoch 23:  94% 120/127 [01:30<00:05,  1.33it/s, loss=1.09, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 23: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.09, v_num=0]\n",
            "Epoch 23: 100% 127/127 [01:35<00:00,  1.33it/s, loss=1.09, v_num=0]Epoch 23, global step 2880: 'val/CER' reached 32.25521 (best 32.25521), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=23-step=2880.ckpt' as top 1\n",
            "Epoch 24:  94% 120/127 [01:31<00:05,  1.31it/s, loss=1.08, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 24: 100% 127/127 [01:35<00:00,  1.32it/s, loss=1.08, v_num=0]\n",
            "Epoch 24: 100% 127/127 [01:35<00:00,  1.32it/s, loss=1.08, v_num=0]Epoch 24, global step 3000: 'val/CER' reached 29.61896 (best 29.61896), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=24-step=3000.ckpt' as top 1\n",
            "Epoch 25:  94% 120/127 [01:31<00:05,  1.31it/s, loss=1.01, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 25: 100% 127/127 [01:35<00:00,  1.34it/s, loss=1.01, v_num=0]\n",
            "Epoch 25: 100% 127/127 [01:35<00:00,  1.34it/s, loss=1.01, v_num=0]Epoch 25, global step 3120: 'val/CER' reached 28.64422 (best 28.64422), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=25-step=3120.ckpt' as top 1\n",
            "Epoch 26:  94% 120/127 [01:32<00:05,  1.29it/s, loss=1.01, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 26: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.01, v_num=0]\n",
            "Epoch 26: 100% 127/127 [01:36<00:00,  1.32it/s, loss=1.01, v_num=0]Epoch 26, global step 3240: 'val/CER' was not in top 1\n",
            "Epoch 27:  94% 120/127 [01:29<00:05,  1.34it/s, loss=1, v_num=0]    \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 27: 100% 127/127 [01:34<00:00,  1.35it/s, loss=1, v_num=0]\n",
            "Epoch 27: 100% 127/127 [01:34<00:00,  1.35it/s, loss=1, v_num=0]Epoch 27, global step 3360: 'val/CER' reached 28.20115 (best 28.20115), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=27-step=3360.ckpt' as top 1\n",
            "Epoch 28:  94% 120/127 [01:30<00:05,  1.32it/s, loss=0.958, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 28: 100% 127/127 [01:36<00:00,  1.32it/s, loss=0.958, v_num=0]\n",
            "Epoch 28: 100% 127/127 [01:36<00:00,  1.32it/s, loss=0.958, v_num=0]Epoch 28, global step 3480: 'val/CER' reached 27.78024 (best 27.78024), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=28-step=3480.ckpt' as top 1\n",
            "Epoch 29:  94% 120/127 [01:29<00:05,  1.34it/s, loss=0.941, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 29: 100% 127/127 [01:33<00:00,  1.36it/s, loss=0.941, v_num=0]\n",
            "Epoch 29: 100% 127/127 [01:33<00:00,  1.36it/s, loss=0.941, v_num=0]Epoch 29, global step 3600: 'val/CER' reached 27.42579 (best 27.42579), saving model to '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=29-step=3600.ckpt' as top 1\n",
            "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "Epoch 29: 100% 127/127 [01:33<00:00,  1.35it/s, loss=0.941, v_num=0]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100% 7/7 [00:02<00:00,  2.47it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m Runningstage.validating \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    27.4257869720459     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.6614975929260254    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   10.700044631958008    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   15.064244270324707    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        val/loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.903721809387207    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:02<00:00,  2.85s/it]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    27.87983512878418    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.5344716310501099    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    9.163604736328125    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   17.181758880615234    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8776531219482422    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "{'val_metrics': [{'val/loss': 0.903721809387207,\n",
            "                  'val/CER': 27.4257869720459,\n",
            "                  'val/IER': 10.700044631958008,\n",
            "                  'val/DER': 1.6614975929260254,\n",
            "                  'val/SER': 15.064244270324707}],\n",
            " 'test_metrics': [{'test/loss': 0.8776531219482422,\n",
            "                   'test/CER': 27.87983512878418,\n",
            "                   'test/IER': 9.163604736328125,\n",
            "                   'test/DER': 1.5344716310501099,\n",
            "                   'test/SER': 17.181758880615234}],\n",
            " 'best_checkpoint': '/content/drive/MyDrive/emg2qwerty/logs/2025-03-15/01-59-20/checkpoints/epoch=29-step=3600.ckpt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGANotiwhngl"
      },
      "source": [
        "#### Testing:\n",
        "\n",
        "- See the output after each training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  checkpoint=\"logs/2025-03-15/01-59-20/checkpoints/last.ckpt\" \\\n",
        "  train=False trainer.accelerator=gpu \\\n",
        "  decoder=ctc_greedy \\\n",
        "  model=tds_conv_ctc \\\n",
        "  hydra.launcher.mem_gb=12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2FYVyRCg7kf",
        "outputId": "1edc8b7f-5e81-4d76-e62a-949a0d03df42"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-03-15 02:54:11,285][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 42\n",
            "batch_size: 32\n",
            "num_workers: 2\n",
            "train: false\n",
            "checkpoint: logs/2025-03-15/01-59-20/checkpoints/last.ckpt\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 42\n",
            "[2025-03-15 02:54:11,289][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-15 02:54:11,412][__main__][INFO] - Loading module from checkpoint logs/2025-03-15/01-59-20/checkpoints/last.ckpt\n",
            "[2025-03-15 02:54:11,597][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/drive/MyDrive/emg2qwerty/logs/2025-03-15/02-54-11/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Validation DataLoader 0: 100% 7/7 [00:03<00:00,  1.85it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m Runningstage.validating \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    27.4257869720459     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.6614975929260254    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   10.700044631958008    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   15.064244270324707    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        val/loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.903721809387207    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:02<00:00,  2.92s/it]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    27.87983512878418    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.5344716310501099    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    9.163604736328125    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   17.181758880615234    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8776531219482422    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "{'val_metrics': [{'val/loss': 0.903721809387207,\n",
            "                  'val/CER': 27.4257869720459,\n",
            "                  'val/IER': 10.700044631958008,\n",
            "                  'val/DER': 1.6614975929260254,\n",
            "                  'val/SER': 15.064244270324707}],\n",
            " 'test_metrics': [{'test/loss': 0.8776531219482422,\n",
            "                   'test/CER': 27.87983512878418,\n",
            "                   'test/IER': 9.163604736328125,\n",
            "                   'test/DER': 1.5344716310501099,\n",
            "                   'test/SER': 17.181758880615234}],\n",
            " 'best_checkpoint': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  checkpoint=\"logs/2025-03-15/01-59-20/checkpoints/epoch\\=29-step\\=3600.ckpt\" \\\n",
        "  train=False trainer.accelerator=gpu \\\n",
        "  decoder=ctc_greedy \\\n",
        "  model=tds_conv_ctc \\\n",
        "  hydra.launcher.mem_gb=12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckfp4LznuStI",
        "outputId": "cc378b38-6f4c-4c89-b357-39ff10d926dc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-03-15 02:55:05,459][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 42\n",
            "batch_size: 32\n",
            "num_workers: 2\n",
            "train: false\n",
            "checkpoint: logs/2025-03-15/01-59-20/checkpoints/epoch=29-step=3600.ckpt\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 42\n",
            "[2025-03-15 02:55:05,462][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-15 02:55:05,576][__main__][INFO] - Loading module from checkpoint logs/2025-03-15/01-59-20/checkpoints/epoch=29-step=3600.ckpt\n",
            "[2025-03-15 02:55:05,759][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/drive/MyDrive/emg2qwerty/logs/2025-03-15/02-55-05/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0:   0% 0/7 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Validation DataLoader 0: 100% 7/7 [00:04<00:00,  1.52it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m Runningstage.validating \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    27.4257869720459     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.6614975929260254    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   10.700044631958008    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m         val/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   15.064244270324707    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        val/loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.903721809387207    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 1/1 [00:02<00:00,  2.91s/it]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
            "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/CER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    27.87983512878418    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/DER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.5344716310501099    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/IER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    9.163604736328125    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/SER         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   17.181758880615234    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8776531219482422    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "{'val_metrics': [{'val/loss': 0.903721809387207,\n",
            "                  'val/CER': 27.4257869720459,\n",
            "                  'val/IER': 10.700044631958008,\n",
            "                  'val/DER': 1.6614975929260254,\n",
            "                  'val/SER': 15.064244270324707}],\n",
            " 'test_metrics': [{'test/loss': 0.8776531219482422,\n",
            "                   'test/CER': 27.87983512878418,\n",
            "                   'test/IER': 9.163604736328125,\n",
            "                   'test/DER': 1.5344716310501099,\n",
            "                   'test/SER': 17.181758880615234}],\n",
            " 'best_checkpoint': ''}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}