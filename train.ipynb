{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvxJOJu4XUIW"
      },
      "source": [
        "### Step 1: Mount the Google Drive\n",
        "\n",
        "Remember to use GPU runtime before mounting your Google Drive. (Runtime --> Change runtime type)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCSU4HrvkVDq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoSL1U8Xbjh"
      },
      "source": [
        "### Step 2: Open the project directory\n",
        "\n",
        "Replace `Your_Dir` with your own path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gfQ17SmkfOK"
      },
      "outputs": [],
      "source": [
        "cd Your_Dir/emg2qwerty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzYfAOEYN4C"
      },
      "source": [
        "### Step 3: Install required packages\n",
        "\n",
        "After installing them, Colab will require you to restart the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFFKvhs4tAp5"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSoRzGXCfUtz"
      },
      "source": [
        "### Step 4: Start your experiments!\n",
        "\n",
        "- Remember to download and copy the dataset to this directory: `Your_Dir/emg2qwerty/data`.\n",
        "- You may now start your experiments with any scripts! Below are examples of single-user training and testing (greedy decoding).\n",
        "- **There are two ways to track the logs:**\n",
        "  - 1. Keep `--multirun`, and the logs will not be printed here, but they will be saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/submitit_logs/`.\n",
        "  - 2. Comment out `--multirun` and the logs will be printed in this notebook, but they will not be saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVuSn4rXhLJa"
      },
      "source": [
        "#### Training\n",
        "\n",
        "- The checkpoints are saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/checkpoints/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n84M6KLmkp2i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-14 04:39:07,511][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 8\n",
            "num_workers: 4\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-14 04:39:07,512][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-14 04:39:07,585][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /home/admin2004lts/projects/emg2qwerty/logs/2025-03-14/04-39-07/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/home/admin2004lts/miniconda3/envs/emg2qwerty/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/home/admin2004lts/miniconda3/envs/emg2qwerty/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/home/admin2004lts/miniconda3/envs/emg2qwerty/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/home/admin2004lts/miniconda3/envs/emg2qwerty/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/home/admin2004lts/miniconda3/envs/emg2qwerty/lib/python3.10/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/home/admin2004lts/miniconda3/envs/emg2qwerty/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 5.3 M \n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "5.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "5.3 M     Total params\n",
            "21.173    Total estimated model params size (MB)\n",
            "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]/home/admin2004lts/miniconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Epoch 0:  95%|████████████▎| 480/507 [02:36<00:08,  3.06it/s, loss=124, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                        | 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                           | 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  95%|████████████▎| 481/507 [02:37<00:08,  3.06it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  95%|████████████▎| 482/507 [02:37<00:08,  3.06it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  95%|████████████▍| 483/507 [02:37<00:07,  3.07it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  95%|████████████▍| 484/507 [02:37<00:07,  3.07it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  96%|████████████▍| 485/507 [02:37<00:07,  3.08it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  96%|████████████▍| 486/507 [02:37<00:06,  3.08it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  96%|████████████▍| 487/507 [02:37<00:06,  3.09it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  96%|████████████▌| 488/507 [02:37<00:06,  3.09it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  96%|████████████▌| 489/507 [02:38<00:05,  3.09it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  97%|████████████▌| 490/507 [02:38<00:05,  3.10it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  97%|████████████▌| 491/507 [02:38<00:05,  3.10it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  97%|████████████▌| 492/507 [02:38<00:04,  3.11it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  97%|████████████▋| 493/507 [02:38<00:04,  3.11it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  97%|████████████▋| 494/507 [02:38<00:04,  3.12it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|████████████▋| 495/507 [02:38<00:03,  3.12it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|████████████▋| 496/507 [02:38<00:03,  3.12it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|████████████▋| 497/507 [02:38<00:03,  3.13it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|████████████▊| 498/507 [02:39<00:02,  3.13it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|████████████▊| 499/507 [02:39<00:02,  3.14it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  99%|████████████▊| 500/507 [02:39<00:02,  3.14it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  99%|████████████▊| 501/507 [02:39<00:01,  3.14it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  99%|████████████▊| 502/507 [02:39<00:01,  3.15it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  99%|████████████▉| 503/507 [02:39<00:01,  3.15it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0:  99%|████████████▉| 504/507 [02:39<00:00,  3.16it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|████████████▉| 505/507 [02:39<00:00,  3.16it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|████████████▉| 506/507 [02:39<00:00,  3.17it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|█████████████| 507/507 [02:39<00:00,  3.17it/s, loss=124, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|█████████████| 507/507 [02:39<00:00,  3.17it/s, loss=124, v_num=0]Epoch 0, global step 480: 'val/CER' reached 1357.04480 (best 1357.04480), saving model to '/home/admin2004lts/projects/emg2qwerty/logs/2025-03-14/04-39-07/checkpoints/epoch=0-step=480.ckpt' as top 1\n",
            "Epoch 1:  95%|███████████▎| 480/507 [02:33<00:08,  3.12it/s, loss=3.27, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                        | 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                           | 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  95%|███████████▍| 481/507 [02:34<00:08,  3.12it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  95%|███████████▍| 482/507 [02:34<00:07,  3.13it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  95%|███████████▍| 483/507 [02:34<00:07,  3.13it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  95%|███████████▍| 484/507 [02:34<00:07,  3.13it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  96%|███████████▍| 485/507 [02:34<00:07,  3.14it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  96%|███████████▌| 486/507 [02:34<00:06,  3.14it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  96%|███████████▌| 487/507 [02:34<00:06,  3.15it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  96%|███████████▌| 488/507 [02:34<00:06,  3.15it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  96%|███████████▌| 489/507 [02:34<00:05,  3.16it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  97%|███████████▌| 490/507 [02:34<00:05,  3.16it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  97%|███████████▌| 491/507 [02:35<00:05,  3.17it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  97%|███████████▋| 492/507 [02:35<00:04,  3.17it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  97%|███████████▋| 493/507 [02:35<00:04,  3.18it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  97%|███████████▋| 494/507 [02:35<00:04,  3.18it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  98%|███████████▋| 495/507 [02:35<00:03,  3.18it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  98%|███████████▋| 496/507 [02:35<00:03,  3.19it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  98%|███████████▊| 497/507 [02:35<00:03,  3.19it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  98%|███████████▊| 498/507 [02:35<00:02,  3.20it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  98%|███████████▊| 499/507 [02:35<00:02,  3.20it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  99%|███████████▊| 500/507 [02:35<00:02,  3.21it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  99%|███████████▊| 501/507 [02:36<00:01,  3.21it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  99%|███████████▉| 502/507 [02:36<00:01,  3.21it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  99%|███████████▉| 503/507 [02:36<00:01,  3.22it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1:  99%|███████████▉| 504/507 [02:36<00:00,  3.22it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1: 100%|███████████▉| 505/507 [02:36<00:00,  3.23it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1: 100%|███████████▉| 506/507 [02:36<00:00,  3.23it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1: 100%|████████████| 507/507 [02:36<00:00,  3.24it/s, loss=3.27, v_num=0]\u001b[A\n",
            "Epoch 1: 100%|████████████| 507/507 [02:36<00:00,  3.24it/s, loss=3.27, v_num=0]Epoch 1, global step 960: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/home/admin2004lts/projects/emg2qwerty/logs/2025-03-14/04-39-07/checkpoints/epoch=1-step=960.ckpt' as top 1\n",
            "Epoch 2:  44%|█████▎      | 222/507 [01:10<01:30,  3.16it/s, loss=3.31, v_num=0]^C\n",
            "/home/admin2004lts/miniconda3/envs/emg2qwerty/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=tds_conv_ctc \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=transformer_encoder_ctc \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=gru_ctc \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=cnn_gru_ctc \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=lstm_ctc \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  model=cnn_lstm_ctc \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGANotiwhngl"
      },
      "source": [
        "#### Testing:\n",
        "\n",
        "- See `test.ipynb`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "emg2qwerty",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
